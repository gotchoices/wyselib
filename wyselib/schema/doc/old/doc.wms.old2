# Store and retrieve documents
#TODO:
#X- Make unique on path, name
#X- Implement update trigger, replace large object if necessary
#X- Implement delete trigger
#X- Can't update/delete a locked object
#- Delete (and archive) large objects that are not found in doc.doc
#- Create maintenance stored procedure to check file/object integrity
#-  Recover from lost large object
#-  Recover from lost or corrupted external file
#- 
#- Move to prod.doc:
#- Implement link table for use with prodim
#- Implement major/minor version numbers
#- Build path as: product basename major minor
#- All files unlocked on working
#- All files locked when committed to production
#- 

namespace eval doc {
    def cksum		{/bin/cksum}
    def doc_root	{/usr/local/share/wyatt-docs}		;#store all docs under here
    def doc_del		"$doc_root/.deleted"			;#any docs deleted or updated out of place
    def logfile		"$doc_root/.vacuum.log"			;#log progress of cleaning/checking
    def doc_stray	"$doc_root/.stray"			;#move files here that don't have a metafile with them
    def doc_pk		{id}
    def doc_v_in	{id path name version exten cmt locked blob}
    def doc_v_up	$doc_v_in
    def doc_se		[concat $doc_v_up size cksum $glob::stampfn]
}
schema doc -grant public

sequence doc.doc_seq {doc} {minvalue 1000}

# Contains an entry for each document
#----------------------------------------------------------------
table doc.doc {doc.doc_seq base.ent} {
    id		int		primary key default nextval('doc.doc_seq')
  , path	varchar[]	not null constraint "doc.doc.IPS" check (path[1] is not null and path[1] != '' and substring(path[1],0,1) != '.')
  , name	varchar		not null constraint "doc.doc.IFN" check (name != '' and name ~ '[^\\*/<>()]' and substring(name,0,1) != '.')
  , version	int		not null constraint "doc.doc.IVN" check (version >= 0)
  , exten	varchar		not null default ''
  , cmt		varchar
  , locked	boolean		default 'f'
  , size	bigint		not null
  , cksum	bigint		not null
  , blob	oid		not null unique
  , constraint "!doc.doc.UFN"	unique	(path,name,version,exten)
    subst($glob::stamps)
}

# Note how some documents depend on others
#----------------------------------------------------------------
table doc.link {doc.doc} {
    outp	int		references doc.doc on update cascade on delete cascade
  , inp		int		references doc.doc on update cascade
  , type	varchar		not null constraint "doc.link.ITP" check (type in ('auto','link','manu','rend'))
}

# When inserting a new document
#----------------------------------------------------------------
function doc.doc_tf_ins() {doc.doc doc.archive(doc.doc,int)} {
  returns trigger language plpgsql as $$
    declare
        tiar	bigint[];
    begin
-- raise notice 'doc_ins:%', new.id;
        if new.version is null then
            new.version := (select coalesce(max(version)+1,0) from doc.doc where path = new.path and name = new.name and exten = new.exten);
        end if;
        tiar := doc.archive(new,1);
        new.size := tiar[1];
        new.cksum := tiar[2];
        return new;
    end;
$$;}
trigger doc_doc_tr_ins {} {before insert on doc.doc for each row execute procedure doc.doc_tf_ins();}

# When updating a document
#----------------------------------------------------------------
function doc.doc_tf_upd() {doc.doc doc.archive(doc.doc,int)} {
  returns trigger language plpgsql as $$
    declare
        tiar	bigint[];
    begin
        if session_user != 'dbadmin()' and old.locked then
            raise exception '!doc.doc.DLK %', old.id;	-- Can't modify locked docs
        end if;

        if not eval(samelist path name version exten) then	-- if we are changing where the file is archived
            if exists (select * from doc.doc where path = new.path and name = new.name and version = new.version and exten = new.exten) then
                raise exception '!doc.doc.CFN % % % %', new.path, new.name, new.version, new.exten;		-- Conflicting record found
            end if;
            tiar := doc.archive(new, 1);
            perform doc.archive(old, 0);
        elseif new.blob != old.blob then			-- same archive name but new file contents
            tiar := doc.archive(new, 1);
            perform lo_unlink(old.blob);			-- get rid of the old large object
        elseif not eval(samelist size cksum) then		-- if trying to change size or checksum
            tiar := doc.archive(new, 1);			-- rearchive, fresh copy
        end if;
        if tiar is not null then				-- if size,cksum got modified
            new.size  := tiar[1];
            new.cksum := tiar[2];
        end if;
        return new;
    end;
$$;}
trigger doc_doc_tr_upd {} {before update on doc.doc for each row execute procedure doc.doc_tf_upd();}

# When deleting a document
#----------------------------------------------------------------
function doc.doc_tf_del() {doc.doc doc.archive(doc.doc,int)} {
  returns trigger language plpgsql as $$
    begin
        if session_user != 'dbadmin()' and old.locked then
            raise exception '!doc.doc.DLK %', old.id;	-- Can't modify locked docs
        end if;
        perform doc.archive(old, 0);
        return old;
    end;
$$;}
trigger doc_doc_tr_del {} {before delete on doc.doc for each row execute procedure doc.doc_tf_del();}

# Store (or delete) a backup copy of the large object in the filesystem
# $1: doc record (new/old)
# $2: 0=delete, 1=store
#----------------------------------------------------------------
function doc.archive(doc.doc,int) {doc.doc} {
  returns bigint[] language pltclu as $$
 
    set path "subst($doc::doc_root)/[join [split [lindex $1(path) 0] ,] /]"
    if {![file exists $path]} {file mkdir $path}
    set base "$1(name)"
    if {$1(version) > 0} {append base "($1(version))"}
    if {$1(exten) != {}} {append base ".$1(exten)"}
    set fname "$path/$base"
    set mfname "$path/.$base"
#elog NOTICE "id:$1(id) path:$path fname:$fname"
    if {!$2} {				;#if deleting
        if {"subst($doc::doc_del)" != {}} {		;#if a delete directory specified
            set dpath "subst($doc::doc_del)/[join [split [lindex $1(path) 0] ,] /]"
            if {![file exists $dpath]} {file mkdir $dpath}
            set suff {}
            set sver 0
            while {[file exists $dpath/$base$suff]} {set suff "-[incr sver]"}
            file rename -force $mfname $dpath/.$base$suff
            file rename -force $fname $dpath/$base$suff
        } else {
            file delete -force $mfname
            file delete -force $fname
        }
        return_null
    }

    spi_exec "select lo_export($1(blob),'$fname')"

    regsub -all {'} $1(cmt) {''} 1(cmt)		;#escape quotes in comment
    set fp [open $mfname w]			;#create file for metadata
    puts $fp [array get 1]
    close $fp
    
    lassign [exec subst($doc::cksum) $fname] cksum size
#elog NOTICE " cksum:$cksum size:$size"
    return "{$size,$cksum}"
$$;}

# Check the integrity of the document database
#----------------------------------------------------------------
# lg_obj	doc	arch	meta	case	action
#     no	 no	 no	yes	1	Oops?		Log if not recent, move metafile to Trash
#     no	 no	yes	 no	2	Stray?		Log error.  Move file to Stray
#     no	 no	yes	yes	3	Failed Trans	If recent, delete, else log and move to Lost
#     no	yes	 no	  ?	4,5	Oops?		Log error.
#     no	yes	yes	  ?	6,7	New DB Regen	Import doc to LO, re-create meta-data
#    yes	 no	  ?	 no	8,A	Oops?		Log and save file by its OID in Orphan
#    yes	 no	 no	yes	9	Oops?		Log if not recent, move meta, LO to Trash
#    yes	 no	yes	yes	B	Oops?		Log if not recent, move meta, arch, LO to Trash
#    yes	yes	 no	  ?	C,D	File Damage	Log, re-write archive and meta
#    yes	yes	yes	 no	E	File Damage	Re-write meta-data
#    yes	yes	yes	yes	F	OK		Check doc against LO size and cksum
#----------------------------------------------------------------
function doc.vacuum() {doc.doc} {
  returns int language pltclu as $$

    #----------------------------------------------------------------
    proc logit {msg} {					;#post to the log file
        set fp [open subst($doc::logfile) a]
        puts $fp "[clock format [clock seconds] -format "%Y-%b-%d_%H:%M:%S"]: $msg"
        close $fp
    }
    #----------------------------------------------------------------
    proc read_file {fname} {				;#return the contents of a file
        set fp [open $fname r]
        set data [read $fp]
        close $fp
        return $data
    }
    #----------------------------------------------------------------
    proc write_file {fname data} {
        set fp [open $fname w]
        puts -nonewline $fp $data
        close $fp
    }

    #----------------------------------------------------------------
    proc check_folder {root dir} {				;#look at all the archive files in dir
        set rdir "$root/$dir"
        foreach sub [glob -nocomplain -tails -types d -directory $rdir *] {
            if {$sub == {.} || $sub == {..}} continue
            check_folder $root $dir/$sub			;#recurse through sub-directories
        }
logit "Folder: $root $dir"
        lassign {} have_both have_arch have_meta
        foreach file [glob -nocomplain -tails -types f -directory $rdir * .*] {
            if {[string range $file 0 0] == {.}} {		;#if this is a hidden file
                set name [string range $file 1 end]		;#its name without the leading dot
                if {[file exists $rdir/$name]} {
                    if {[lsearch -exact $have_both $name] < 0} {lappend have_both $name}
                } else {
                    lappend have_meta $name
                }
            } else {						;#this is a regular file
                if {[file exists $rdir/.$file]} {
                   if {[lsearch -exact $have_both $file] < 0} {lappend have_both $file}
               } else {
                   lappend have_arch $file
               }
            }
        }
logit "  Both:$have_both"
logit "  Stray archives:$have_arch meta:$have_meta"
        set query {}
        foreach file $have_both {				;#where we found a data file and a meta file
            lassign [exec subst($doc::cksum) $rdir/$file] cksum size
            array set meta [read_file $rdir/.$file]				;#get the meta-data
            if {![info exists meta(size)] || ![info exists meta(cksum)]} {	;#invalid meta file
                logit "Invalid meta file: $rdir/.$file"
                lappend have_arch $file
                continue
            }
logit "   meta:[array get meta]"
            append query "insert into doc_arch_tmp (id,path,name,version,exten,size,cksum,blob,asize,acksum) values ($meta(id),'$meta(path)','$meta(name)',$meta(version),'$meta(exten)',$meta(size),$meta(cksum),$meta(blob),$size,$cksum);\n"
            array unset meta
        }
        foreach file $have_meta {				;#where we found only a meta file
            set data [read_file $rdir/.$file]
            if {[llength $data] != 32} {
                logit "Unexpected contents for meta data file: $rdir/.$file.  Moving to stray dir."
logit "                file rename -force $rdir/.$file subst($doc::doc_stray)"
                continue
            }
            array set meta $data
            append query "insert into doc_arch_tmp (id,path,name,version,exten,size,cksum,blob) values ($meta(id),'$meta(path)','$meta(name)',$meta(version),'$meta(exten)',$meta(size),$meta(cksum),$meta(blob));\n"
        }
        foreach file $have_arch {				;#where we found only a data file
            set path "{[join [split $dir /] ,]}"
            set exten [string range [file extension $file] 1 end]
            set base [file rootname [file tail $file]]
            lassign [exec subst($doc::cksum) $rdir/$file] cksum size
            if {![regexp {(.*)\(([0-9]+)\)} $base junk name version]} {set name $base; set version 0}
            append query "insert into doc_arch_tmp (path,name,version,exten,asize,acksum) values ('$path','$name',$version,'$exten',$size,$cksum);\n"
        }
logit "query:$query"
        spi_exec $query
    }

    logit {Starting}
    set changes 0

    spi_exec {
        create temporary table doc_arch_tmp (id int, path varchar[], name varchar, version int, exten varchar, size bigint, cksum bigint, blob int, asize bigint, acksum bigint);
    }
    foreach dir [glob -nocomplain -tails -directory subst($doc::doc_root) -types d *] {
        check_folder subst($doc::doc_root) $dir
    }

    logit "Finished with changes: $changes"
    return $changes
$$;}

# Basic view
#----------------------------------------------------------------
view doc.doc_v {doc.doc} {select
    eval(fld_list $doc::doc_se d)
  , array_to_string(d.path,'/') || '/' || d.name || case when d.version <= 0 then '' else '(' || d.version || ')' end || '.' || d.exten	as filename
    
    from	doc.doc		d
}

return





# After any change
#----------------------------------------------------------------
function doc.doc_tf_chk() {doc.doc doc.archive(doc.doc,int)} {
  returns trigger language plpgsql as $$
    declare
        trec	doc.doc;
        tid	int;
    begin
        trec.version := 0;
        trec.exten := '';
        trec.path := array['_orphan'];		-- for each orphan, store it in the _orphan folder
        for tid in select loid from pg_largeobject lo where pageno = 0 and not exists (select blob from doc.doc where blob = lo.loid) loop
            trec.name := tid::varchar;		-- Make a name from its oid
            perform doc.archive(trec, 1);	-- Archive it
raise notice 'Orphan:%', tid;
--            perform lo_unlink(tid);		-- and delete the large object from the database
        end loop;
        return old;
    end;
$$;}
trigger doc_doc_tr_chk {} {after insert or update or delete on doc.doc for each statement execute procedure doc.doc_tf_chk();}


# Fetch a document from the filesystem
#----------------------------------------------------------------
function doc.doc_fetch() {doc.doc} {
  returns varchar language plpgsql as $$
    begin
        return old;
    end;
$$;}
